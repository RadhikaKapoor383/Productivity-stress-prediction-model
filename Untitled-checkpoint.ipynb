{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd858bdb-f088-4e25-8dbc-31f77ce61d46",
   "metadata": {},
   "source": [
    "# **Model - Stress Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716b39a-a470-498c-924a-551ffcce8b99",
   "metadata": {},
   "source": [
    "## Stage 1: Retrieving and loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01810cd0-6864-46ae-bfca-c03a4e291456",
   "metadata": {},
   "source": [
    "As the first step, we load our dataset and provide some initial overview on the data through shape, columns and info methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0353f92-ee41-4c41-a247-827aef617dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hours_Coding  Lines_of_Code  Bugs_Found  Bugs_Fixed  AI_Usage_Hours  \\\n",
      "0             7            416           9           7               6   \n",
      "1             4            269          16          13               5   \n",
      "2            11            439           3           0               2   \n",
      "3             8            472          15           9               4   \n",
      "4             5            265          19          16               5   \n",
      "\n",
      "   Sleep_Hours  Cognitive_Load  Task_Success_Rate  Coffee_Intake  \\\n",
      "0          5.9              92                 34              7   \n",
      "1          5.1              85                 36              2   \n",
      "2          6.2              38                 79              2   \n",
      "3          4.2              26                 94              5   \n",
      "4          8.1              82                 33              6   \n",
      "\n",
      "   Stress_Level  Task_Duration_Hours  Commits  Errors  \n",
      "0            99                 10.5       20       3  \n",
      "1           100                  9.5       17       8  \n",
      "2            55                 18.3       35       2  \n",
      "3            30                 12.6       28       4  \n",
      "4            82                  7.0       25       9  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'AI_Developer_Performance.csv';\n",
    "data = pd.read_csv(file_path);\n",
    "print(data.head());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a02943-9853-49ba-a185-1d1bad5b506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data (rows, columns): (1000, 13)\n",
      "Columns in data: ['Hours_Coding', 'Lines_of_Code', 'Bugs_Found', 'Bugs_Fixed', 'AI_Usage_Hours', 'Sleep_Hours', 'Cognitive_Load', 'Task_Success_Rate', 'Coffee_Intake', 'Stress_Level', 'Task_Duration_Hours', 'Commits', 'Errors']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Hours_Coding         1000 non-null   int64  \n",
      " 1   Lines_of_Code        1000 non-null   int64  \n",
      " 2   Bugs_Found           1000 non-null   int64  \n",
      " 3   Bugs_Fixed           1000 non-null   int64  \n",
      " 4   AI_Usage_Hours       1000 non-null   int64  \n",
      " 5   Sleep_Hours          1000 non-null   float64\n",
      " 6   Cognitive_Load       1000 non-null   int64  \n",
      " 7   Task_Success_Rate    1000 non-null   int64  \n",
      " 8   Coffee_Intake        1000 non-null   int64  \n",
      " 9   Stress_Level         1000 non-null   int64  \n",
      " 10  Task_Duration_Hours  1000 non-null   float64\n",
      " 11  Commits              1000 non-null   int64  \n",
      " 12  Errors               1000 non-null   int64  \n",
      "dtypes: float64(2), int64(11)\n",
      "memory usage: 101.7 KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the data (rows, columns): {data.shape}\")\n",
    "print(f\"Columns in data: {list(data.columns)}\\n\")\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc98e4e8-58de-4197-8c78-4a15cca7f7fa",
   "metadata": {},
   "source": [
    "#### Initial Data Quality Assessment\n",
    "\n",
    "- All variables are numerical, which makes the dataset suitable for\n",
    "  regression modeling without categorical encoding.\n",
    "- No missing values were observed at this stage.\n",
    "- The dataset is well-structured and ready for further preprocessing steps.\n",
    "\n",
    "This confirms that the data is accessible, complete, and appropriate for\n",
    "stress level prediction using machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd996b-bd4c-4e19-9e71-639d7b6cd020",
   "metadata": {},
   "source": [
    "## Stage 2: Data Preparation\n",
    "In this section, we prepare the dataset for stress level prediction. \n",
    "This includes:\n",
    "1. Data Cleansing : removing duplicates, missing or invalid values.\n",
    "2. Data Transformation : feature engineering and scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dabcdf-669c-40e4-be1b-a999ca250148",
   "metadata": {},
   "source": [
    "### 2.1 Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ba8ea-dfb2-4c06-817e-01b04ed76d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    df = data.drop_duplicates()\n",
    "    print(\"Duplicates removed.\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009797d-2582-4e81-bb20-4ace71e4da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isnull().sum();\n",
    "print(f'Number of missing values in each column:\\n {missing_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812d001-d6d2-4a90-acea-6e589472535b",
   "metadata": {},
   "source": [
    "No missing values were found in the dataset, indicating completeness\n",
    "and suitability for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c1a08-b5b3-4685-a7a0-db2e73957946",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_coding_hours = data[(data['Hours_Coding'] <= 0) | (data['Hours_Coding'] >= 24)].shape[0]\n",
    "invalid_lines = data[data['Lines_of_Code'] < 0].shape[0]\n",
    "invalid_bugs = data[data['Bugs_Found'] < 0].shape[0]\n",
    "invalid_bugs_fixed = data[data['Bugs_Fixed'] < 0].shape[0]\n",
    "invalid_sleep_hours = data[(data['Sleep_Hours'] <= 0) | (data['Sleep_Hours'] >= 24)].shape[0]\n",
    "invalid_AI_hours = data[(data['AI_Usage_Hours'] < 0) | (data['AI_Usage_Hours'] > 24)].shape[0]\n",
    "invalid_coffee = data[data['Coffee_Intake'] < 0].shape[0]\n",
    "invalid_task_hours = data[(data['Task_Duration_Hours'] <= 0)].shape[0]\n",
    "\n",
    "print(f\"Invalid Coding Hours: {invalid_coding_hours}\")\n",
    "print(f\"Invalid Lines of Code: {invalid_lines}\")\n",
    "print(f\"Invalid Bugs Found: {invalid_bugs}\")\n",
    "print(f\"Invalid Bugs Fixed: {invalid_bugs_fixed}\")\n",
    "print(f\"Invalid Sleep Hours: {invalid_sleep_hours}\")\n",
    "print(f\"Invalid AI Usage Hours: {invalid_AI_hours}\")\n",
    "print(f\"Invalid Coffee Intake: {invalid_coffee}\")\n",
    "print(f\"Invalid Task Duration Hours: {invalid_task_hours}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2db697-2ab4-43c7-ac12-84a0b0ef47ab",
   "metadata": {},
   "source": [
    "All values are within reasonable ranges.\n",
    "This confirms the dataset is clean and ready for feature engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01271213-1352-4421-9e6c-a3d8d08a5b3e",
   "metadata": {},
   "source": [
    "### 2.2 Feature Engineering\n",
    "\n",
    "We create new features that may improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f527b7-e605-45b7-9742-f070e7851a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Bug_Fix_Ratio'] = np.where(data['Bugs_Found'] > 0, data['Bugs_Fixed'] / data['Bugs_Found'], 0)\n",
    "data['Bug_Fix_Ratio'] = data['Bug_Fix_Ratio'].round(2)\n",
    "print(data[['Bugs_Fixed','Bugs_Found','Bug_Fix_Ratio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f474a9-24da-4203-a00b-a3eb6cfe8291",
   "metadata": {},
   "source": [
    "The Bug_Fix_Ratio measures how efficiently a developer fixes the bugs \n",
    "they encounter. A higher value indicates better debugging efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1914b3-47a6-4cd7-9f26-4f9dc6c9b8f9",
   "metadata": {},
   "source": [
    "### 2.3 Selecting Features and Target \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffb668-e859-48b2-b298-61eef6aada26",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Hours_Coding', 'Lines_of_Code', 'Bugs_Found', 'Bugs_Fixed','AI_Usage_Hours', 'Sleep_Hours', \n",
    "            'Cognitive_Load','Coffee_Intake', 'Task_Duration_Hours', 'Commits','Errors', 'Bug_Fix_Ratio']\n",
    "\n",
    "target_stress = 'Stress_Level'\n",
    "\n",
    "X = data[features]\n",
    "Y = data[target_stress]\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd7a3f-69f7-484d-91e8-2e57a1db1df8",
   "metadata": {},
   "source": [
    "### 2.4 Feature Scaling\n",
    "\n",
    "Since input features have different scales, we standardize them \n",
    "using StandardScaler. This ensures that features contribute equally \n",
    "to the regression model and improves convergence for some algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7b84e-e49e-46a0-b7e9-f9ddbcc030f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "print(X_scaled.head());\n",
    "\n",
    "Y_DF = pd.DataFrame(Y)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "Y_scaled = y_scaler.fit_transform(Y_DF)\n",
    "\n",
    "Y_scaled = pd.DataFrame(Y_scaled, columns=[target_stress])\n",
    "print(Y_scaled.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e4e685-198e-478f-bc8a-13840aefd05e",
   "metadata": {},
   "source": [
    "### Summary of Data Preparation\n",
    "\n",
    "- Duplicate rows and missing values were checked; none required removal.\n",
    "- Feature engineering created Bug_Fix_Ratio to capture debugging efficiency.\n",
    "- Input features and target variable were separated for modeling.\n",
    "- Features were standardized to ensure uniform contribution to regression.\n",
    "\n",
    "The dataset is now clean, transformed, and ready for exploratory data analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6ad7f-7f91-43bb-a95d-ca21dfc65030",
   "metadata": {},
   "source": [
    "## Stage 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8c1fb-fa98-4dd6-bf2a-f47d37f7e95e",
   "metadata": {},
   "source": [
    "### 3.1 Descriptive Statistics\n",
    "\n",
    "We begin by summarizing the central tendency, dispersion, and range \n",
    "of all features and the target variable Stress_Level. \n",
    "Descriptive statistics help identify potential outliers and understand \n",
    "overall variability in developer behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b7f3b-ca8b-4ec7-8579-522690321415",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_stats = data[features + [target_stress]].describe().T\n",
    "desc_stats['variance'] = data[features + [target_stress]].var()\n",
    "desc_stats['skewness'] = data[features + [target_stress]].skew()\n",
    "\n",
    "desc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e07ba-957b-45ea-b62d-6c8db5de0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "combined_scaled = pd.concat([X_scaled, Y_scaled], axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=combined_scaled, orient='h')\n",
    "plt.title('Boxplot of Features and Stress Level')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0008a08e-5821-4ff6-9621-7f580bc375ed",
   "metadata": {},
   "source": [
    "The boxplot shows the distribution of Stress Level after scaling. Stress levels have moderate spread with the median near the center, indicating most observations cluster around average stress, with some higher and lower cases. Outliers represent relative extremes, not errors.\n",
    "\n",
    "Scaling X and Y was necessary because original features had different ranges, ensuring fair comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262e111-269d-46e5-8354-5f6ddf77bed8",
   "metadata": {},
   "source": [
    "\n",
    "The descriptive statistics provide insights such as:\n",
    "- Mean and median values for working hours, sleep, cognitive load, and stress levels.\n",
    "- Minimum and maximum values to spot extreme cases.\n",
    "- Standard deviation to assess variability among developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84deb76-d1dd-45b8-953b-589bdbe4f824",
   "metadata": {},
   "source": [
    "### 3.2 Distribution Analysis\n",
    "\n",
    "We visualize the distribution of key variables to understand patterns \n",
    "and skewness. This helps in detecting imbalances or unusual trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c24089-f262-45ad-8740-48328677d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(data['Stress_Level'], bins=15, kde=True, color='Tomato')\n",
    "plt.title('Distribution of Stress Level')\n",
    "plt.xlabel('Stress Level')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(data['Sleep_Hours'], bins=15, kde=True, color='Skyblue')\n",
    "plt.title('Distribution of Sleep Hours')\n",
    "plt.xlabel('Sleep Hours')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(data['Hours_Coding'], bins=15, kde=True, color='green')\n",
    "plt.title('Distribution of Hours Coding')\n",
    "plt.xlabel('Hours Coding')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7997c967-25e5-418c-8ec9-34decc62d9cd",
   "metadata": {},
   "source": [
    "- Stress Level: Mostly uniform, with a spike at the high end showing a group under extreme stress.\n",
    "- Sleep Hours: Uniformly spread between 4–9 hours, with 6 hours slightly more common.\n",
    "- Coding Hours: Multimodal, indicating different patterns or groups of developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9de309-ec6b-478f-a402-4c6d8409d7f3",
   "metadata": {},
   "source": [
    "### 3.3 Relationship Analysis\n",
    "\n",
    "We analyze relationships between stress levels and key features \n",
    "to identify potential predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc176deb-a4c6-4dc5-984b-7b2cec4b8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x='Sleep_Hours',y='Stress_Level',data=data,color='purple')\n",
    "plt.title('Sleep Hours vs Stress Level')\n",
    "plt.xlabel('Sleep Hours')\n",
    "plt.ylabel('Stress Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59517b-9645-4b8c-a278-7666a2bb3af2",
   "metadata": {},
   "source": [
    "The scatter plot shows a wide dispersion of stress levels across all sleep durations (4–9 hours). There is no clear linear or nonlinear trend between sleep hours and stress level. High and low stress values appear at nearly all sleep durations, indicating a weak or negligible relationship between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59801c-8d70-4dba-bf29-3dbfeb9235ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x='Cognitive_Load', y='Stress_Level', data=data, color='orange')\n",
    "plt.title('Stress_Level vs Cognitive_Load')\n",
    "plt.xlabel('Cognitive Load')\n",
    "plt.ylabel('Stress Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7054e9-9303-4cbe-86bb-8b6d0336232b",
   "metadata": {},
   "source": [
    "The scatter plot shows a strong positive relationship between cognitive load and stress level. As cognitive load increases, stress levels also rise in a nearly linear pattern, indicating that higher mental demands are associated with higher stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e88be-5df2-4869-8d81-2fb46dec481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x='AI_Usage_Hours', y='Stress_Level', data=data, color='green')\n",
    "plt.title('Stress_Level vs AI_Usage_Hours')\n",
    "plt.xlabel('AI Usage Hours')\n",
    "plt.ylabel('Stress Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c158d9-55fc-43cc-9301-f37308030913",
   "metadata": {},
   "source": [
    "The scatter plot shows stress levels (≈30–100) across AI usage hours (0–6). Stress values are widely spread at every usage level, indicating no clear trend or strong correlation between AI usage hours and stress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0b86f-2837-45c6-a300-9eef6db404d2",
   "metadata": {},
   "source": [
    "### 3.4 Correlation Analysis\n",
    "\n",
    "We compute pairwise correlations to identify the strongest predictors \n",
    "of stress and detect multicollinearity among features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4471aaa1-0cf7-4f85-8ba7-1b2afdb1c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data[features + [target_stress]].corr().round(2)\n",
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06785dac-5483-40ca-93e0-38ec3bc7cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a381656-cc3e-4bbf-a1f5-13486c6f4803",
   "metadata": {},
   "source": [
    "The heatmap shows stress level is strongly linked to cognitive load, with higher mental workload increasing stress. Most other factors, like AI usage, sleep, coding time, commits, and errors, show weak or no correlation.\n",
    "\n",
    "Strong relationships also appear between hours coding and lines of code, and between bugs found and bugs fixed. Overall, stress is mainly driven by cognitive demands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfcce8e-ee83-491a-94ee-7deece4b663a",
   "metadata": {},
   "source": [
    "**EDA Summary**\n",
    "\n",
    "- Stress_Level varies moderately, suitable for regression.\n",
    "- Sleep_Hours and Cognitive_Load strongly relate to stress.\n",
    "- Workload features show expected correlations.\n",
    "- No major anomalies affect modeling.\n",
    "\n",
    "These insights inform feature selection and model choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd496009-9e47-474b-a8cf-e93941e79b9b",
   "metadata": {},
   "source": [
    "## **4. Stress Level Prediction Model**\n",
    "\n",
    "### 4.1 Model Selection\n",
    "\n",
    "The target variable Stress_Level is continuous, therefore Linear Regression \n",
    "is selected as the appropriate modeling technique.\n",
    "Linear Regression models the relationship between stress levels and multiple \n",
    "independent variables by fitting a linear equation to the observed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93e93d-a909-4169-98b0-27cd0df0c143",
   "metadata": {},
   "source": [
    "### 4.2 Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c97193-c607-4922-b3ce-b317926e5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "print(\"Training samples: \", X_train.shape[0])\n",
    "print(\"Testing samples: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d605ad2-d339-4656-b0de-f5230be059d3",
   "metadata": {},
   "source": [
    "### 4.3 Model Training\n",
    "\n",
    "The Linear Regression model is trained using the training dataset \n",
    "to learn the relationship between input features and stress levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ae6de-8e00-48a3-8683-f63df2690cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR_model = LinearRegression();\n",
    "\n",
    "LR_model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293b3ae-9e57-4eab-a757-ed02c3e8ac1a",
   "metadata": {},
   "source": [
    "### 4.4 Model interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748779d2-1e51-474c-adcd-79a980c58b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({'Feature': features,'Coefficient': LR_model.coef_}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(\"Intercept:\", LR_model.intercept_)\n",
    "display(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef7e09d-8c5a-402e-8abd-5c86a9502421",
   "metadata": {},
   "source": [
    "The table shows how each feature affects Stress_Level in the linear regression model:\n",
    "\n",
    "- Positive coefficients increase stress; negative coefficients decrease stress.\n",
    "- Cognitive_Load (21.32) has the largest impact.\n",
    "- Bugs_Fixed (1.44) and Task_Duration_Hours (0.15) slightly increase stress.\n",
    "- Bug_Fix_Ratio (-0.76) and Bugs_Found (-0.85) reduce stress.\n",
    "- Sleep_Hours and Coffee_Intake have smaller negative effects.\n",
    "\n",
    "The intercept represents stress when all features are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda14e32-2355-4c85-abe2-a8e85eb29858",
   "metadata": {},
   "source": [
    "### 4.5 Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71aed9-bf13-43ab-8178-7ba2a026edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = LR_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1142aee-e415-4944-afbb-b35583955b8f",
   "metadata": {},
   "source": [
    "### 4.6 Actual vs Predicted Stress_Level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d92c56-9253-4271-bd07-7f7627eadbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = pd.concat([\n",
    "    X_test.reset_index(drop=True),\n",
    "    pd.DataFrame(Y_test).reset_index(drop=True),\n",
    "    pd.DataFrame(Y_predicted, columns=['Predicted_Stress']).reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "results_table['Residuals'] = results_table['Stress_Level'] - results_table['Predicted_Stress']\n",
    "\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8da39-6522-4876-92af-1e67151d5d5a",
   "metadata": {},
   "source": [
    "The table shows test set results: features, actual Stress_Level, predicted Stress, and residuals. Positive residuals mean underestimation, negative means overestimation. This helps assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6f6d8-066d-44bf-9522-d7c25dd759ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test, Y_predicted, color='blue', label='Predictions')\n",
    "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], \n",
    "         color='red', linestyle='--', label='Perfect Fit')\n",
    "plt.xlabel(\"Actual Stress_Level\")\n",
    "plt.ylabel(\"Predicted Stress_Level\")\n",
    "plt.title(\"Actual vs Predicted Stress_Level\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267a75e6-dac4-4203-885b-d016481c5e5b",
   "metadata": {},
   "source": [
    "The scatter plot compares predicted vs actual stress. The red line shows perfect predictions. Most points are close to the line, with small deviations and randomly distributed residuals, indicating good model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ff3f1-0da6-43f5-abd9-3b1324bd73a3",
   "metadata": {},
   "source": [
    "### 4.7 Model Evaluation\n",
    "The Linear Regression model is evaluated using MAE, RMSE and R-square.\n",
    "These metrics confirm the model’s accuracy and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa910798-c80b-480e-a183-bedbaedb90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "mae = mean_absolute_error(Y_test, Y_predicted)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, Y_predicted))\n",
    "r2 = r2_score(Y_test, Y_predicted)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b22744-c6f6-47f2-bc3c-c0d4dcde83b2",
   "metadata": {},
   "source": [
    "- MAE = 4.75: Predictions differ from actual stress by about 4.75 units on average.\n",
    "- RMSE = 5.56: Larger errors are limited, showing reliable predictions.\n",
    "- R² = 0.93: The model explains 93% of stress variability.\n",
    "\n",
    "These evaluation metrics confirm that the Linear Regression model provides reliable stress predictions and offers interpretable insights into how workload and lifestyle factors influence developer stress.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c04db6c-2df0-40f5-b78b-ff72b5b12148",
   "metadata": {},
   "source": [
    "### 4.8 Prediction Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7248d-a830-451a-b897-22ce971ab878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'Hours_Coding': [6],\n",
    "    'Lines_of_Code': [350],\n",
    "    'Bugs_Found': [10],\n",
    "    'Bugs_Fixed': [7],\n",
    "    'AI_Usage_Hours': [3],\n",
    "    'Sleep_Hours': [6.5],\n",
    "    'Cognitive_Load': [57],\n",
    "    'Coffee_Intake': [3],\n",
    "    'Task_Duration_Hours': [8],\n",
    "    'Commits': [17],\n",
    "    'Errors': [5],\n",
    "    'Bug_Fix_Ratio': [0.7]\n",
    "})\n",
    "\n",
    "new_data = new_data[features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "new_data_scaled = pd.DataFrame(scaler.transform(new_data), columns=features)\n",
    "\n",
    "predicted_stress = LR_model.predict(new_data_scaled)\n",
    "print(f\"Predicted Stress Level: {predicted_stress[0]:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e649c1f-a2e0-42c2-b3c5-8e8aaa24c56d",
   "metadata": {},
   "source": [
    "## Stage 5: Results and discussion\n",
    "\n",
    "**Results and discussions are summarized in the report.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff7c05-f3e2-4c8c-8c59-3e4f8cdae163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
